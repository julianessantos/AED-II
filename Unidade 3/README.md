# An√°lise de Grafos em Livros de Stephen King: Joyland e Depois
## üé°Introdu√ß√£o
Neste artigo, iremos explorar a an√°lise de grafos aplicada aos textos dos livros Joyland e Depois de Stephen King, com o objetivo de entender as intera√ß√µes e a complexidade das narrativas atrav√©s de entidades e suas conex√µes. A utiliza√ß√£o dos grafos ir√° permitir uma vis√£o mais visual e quantitativa das rela√ß√µes entre personagens e os elementos do enredo, ajudando a explorar caracter√≠sticas como a densidade de personagens, as conex√µes entre entidades e a centralidade dos personagens na trama.

## üìåObjetivos
O principal objetivo deste estudo foi construir redes de entidades com base nos textos de Joyland e Depois, identificando as rela√ß√µes entre personagens, locais e organiza√ß√µes. A partir disso, comparamos as diferen√ßas e semelhan√ßas nos grafos, focando especialmente nos seguintes aspectos:

- **Conex√µes entre Entidades**: An√°lise das intera√ß√µes entre personagens, locais e organiza√ß√µes.
- **Centralidade dos Personagens**: Identifica√ß√£o dos personagens mais influentes na narrativa, com base na sua centralidade no grafo.

O acesso √†s redes interativas feitas no software Gephi podem ser visualizadas nestes dois links: [Joyland](https://julianessantos.github.io/NetworkSites/RedeJoyland/RedeNetworkJoyland/) e [Depois](https://julianessantos.github.io/NetworkSites/RedeDepois/networkDepois/)

## üìãFerramentas Utilizadas
Para realizar essa an√°lise, utilizamos as seguintes ferramentas e bibliotecas:

- Python: Linguagem de programa√ß√£o principal para processamento de dados e gera√ß√£o de grafos.
- spaCy: Para processamento de linguagem natural (PoS Tagging e NER), identificando e extraindo entidades do texto.
- NetworkX: Para constru√ß√£o e an√°lise dos grafos, incluindo c√°lculo de m√©tricas como centralidade e densidade.
- Gephi: Software utilizado para modificar e visualizar grafos de forma interativa.

## üîéDataset
Os dados para a constru√ß√£o das redes foram extra√≠dos dos textos de ambos os livros. Entretanto, foi necess√°rio realizar uma limpeza inicial nos arquivos .txt para uma melhor utiliza√ß√£o dos dados presentes nos livros.

### Limpeza dos Dados
O passo inicial foi eliminar as linhas de cabe√ßalho e rodap√© presentes nos livros, que n√£o contribuem para a constru√ß√£o dos grafos. Como, caso a remo√ß√£o do cabe√ßalho fosse feita primeiro, o n√∫mero de linhas do rodap√© seria modificado, iniciamos a limpeza retirando o rodap√© para, logo em seguida, remover o cabe√ßalho.

Para a execu√ß√£o dessa atividade, foi aplicado um comando !sed, vis√≠vel no bloco de c√≥digo abaixo:
```
#Rodap√©
# Para o Livro 1 (Joyland)
!sed -i '6043,6055d' Joyland_StephenKing.txt # Remove linhas 6043 a 6055
# Para o Livro 2 (Depois)
!sed -i '4676,4902d' Depois_StephenKing.txt # Remove linhas 4500 a 4550

# Cabe√ßalho
# Para o Livro 1 (Joyland)
!sed -i '1,105d' Joyland_StephenKing.txt # Remove linhas 1 a 105
# Para o Livro 2 (Depois)
!sed -i '1,175d' Depois_StephenKing.txt # Remove linhas 1 a 175
```
Os n√∫meros e o arquivo ‚Äúlivro.txt‚Äù s√£o exemplos e podem ser ajustados conforme a necessidade e tamanho do projeto.

Logo em seguida, aplicamos uma limpeza mais profunda, onde foi poss√≠vel realizar a remo√ß√£o de linhas vazias ou que possuem apenas espa√ßos, a remo√ß√£o de espa√ßos extras, a normaliza√ß√£o de espa√ßos m√∫ltiplos entre palavras, a corre√ß√£o de pontua√ß√µes e, por fim, a convers√£o de todo o texto para min√∫sculas.

Esse processo garantiu que os dados ficassem mais uniformes e prontos para a an√°lise posterior. A seguir, um exemplo do comando utilizado para essas opera√ß√µes:

```
# Fun√ß√£o para limpar o texto
def clean_text(file_path, output_path):
    with open(file_path, 'rt', encoding='utf-8') as file:
        lines = file.readlines()

    cleaned_lines = []
    for line in lines:
        # Remover linhas vazias ou apenas com espa√ßos
        if not line.strip():
            continue

        # Normalizar espa√ßos e pontua√ß√£o
        line = line.strip()  # Remove espa√ßos extras no in√≠cio e fim
        line = " ".join(line.split())  # Remove espa√ßos m√∫ltiplos entre palavras
        line = line.replace(" ,", ",").replace(" .", ".")  # Corrigir v√≠rgulas e pontos
        line = line.replace(" ?", "?").replace(" !", "!")  # Corrigir interroga√ß√£o/exclama√ß√£o

        # Transformar em min√∫sculas (opcional, dependendo da an√°lise futura)
        line = line.lower()

        cleaned_lines.append(line)

    # Salvar o texto limpo em um novo arquivo
    with open(output_path, 'w', encoding='utf-8') as output_file:
        output_file.write("\n".join(cleaned_lines))
    print(f"Texto limpo salvo em: {output_path}")
```
### An√°lise de PoS Tagging e NER
Ap√≥s a limpeza, devemos realizar a identifica√ß√£o das categorias gramaticais (PoS) e entidades nomeadas (NER). Para isso, iremos baixar o modelo de linguagem em portugu√™s maior do spaCy, denominado pt_core_news_lg. O comando para instalar e carregar o modelo √© o seguinte:
```
!python -m spacy download pt_core_news_lg
```
Com isso, iremos agora realizar uma an√°lise gramatical do texto, identificando os tipos de palavras e preparando o texto para an√°lises mais avan√ßadas. Vamos ent√£o utilizar o bloco de c√≥digo a seguir para fazer essa extra√ß√£o:

```
# Carregar modelo de linguagem em portugu√™s (vers√£o maior)
nlp = spacy.load("pt_core_news_lg")

# Carregar o arquivo limpo.txt
with open('Joyland_cleaned.txt', 'r', encoding='utf-8') as file:
    text = file.read()

# Limpeza adicional dos textos (remo√ß√£o de espa√ßos extras)
joyland_cleaned = ' '.join(text.split())  # Limpeza do texto

# Processando o texto limpo
doc1 = nlp(joyland_cleaned)

# Exibindo todos os tokens no texto (sem segmenta√ß√£o de senten√ßas)
print("Tokens do texto:")
for token in doc1:
    print(f"{token.text}: {token.tag_}")  # Token e sua tag PoS
```
Logo ap√≥s, iremos fazer uma filtragem para apresentar apenas as entidades espec√≠ficas, sendo elas:

- ‚ÄòPER‚Äô (pessoa),
- ‚ÄòORG‚Äô (organiza√ß√£o),
- ‚ÄòGPE‚Äô (localiza√ß√£o geopol√≠tica, como pa√≠ses ou cidades),
- ‚ÄòLOC‚Äô (outros tipos de localiza√ß√µes, como regi√µes ou pontos geogr√°ficos),
- ‚ÄòPROPN‚Äô (nomes pr√≥prios).
```
# Filtragem para incluir outras entidades al√©m de 'PERSON', 'ORG', 'GPE'
print("\nEntidades nomeadas no texto Joyland (PERSON, ORG, GPE, LOC, PROPN):")
for ent in doc1.ents:
    if ent.label_ in ['PER', 'ORG', 'GPE', 'LOC', 'PROPN']:
        print(f"{ent.text}: {ent.label_}")
```
O objetivo desse c√≥digo √© apresentar algo semelhante a:

- Joyland: LOC
- Stephen King: PER
- Disney: ORG

## üììFundamenta√ß√£o te√≥rica
### Como Funciona a Constru√ß√£o do Grafo?
Ao t√©rmino do processo de limpeza do texto e extra√ß√£o das entidades relevantes, passamos para a constru√ß√£o dos grafos. Por√©m, √© necess√°rio uma breve explica√ß√£o dos conceitos principais de um grafo e das m√©tricas abordadas e suas explica√ß√µes.

- N√≥s: √â um ponto em um grafo. No estudo de caso, cada entidade identificada se tornou um n√≥ no grafo.
- Arestas: √â uma conex√£o entre dois n√≥s em um grafo. Nesse caso, se duas entidades apareciam na mesma senten√ßa, uma aresta era criada entre elas. Isso representava uma intera√ß√£o ou conex√£o narrativa.
Esses grafos permitem observar visualmente como as entidades est√£o relacionadas, identificando clusters e destacando personagens centrais.

### M√©tricas de um grafo
O c√≥digo apresentado no in√≠cio do texto disp√µe de um bloco de c√≥digos feitos especificamente para o c√°lculo de algumas m√©tricas, que seria a fun√ß√£o calcular_metricas(). S√£o essas m√©tricas apresentadas:
- N√∫mero de n√≥s (Nodes): Refere-se √† quantidade de v√©rtices ou entidades presentes no grafo.
- N√∫mero de arestas (Edges): Refere-se √† quantidade de conex√µes entre os n√≥s do grafo.
- Centralidade de grau (Degree Centrality): Mede a import√¢ncia de um n√≥ com base no n√∫mero de conex√µes que ele tem. Quanto maior o n√∫mero de conex√µes, maior a centralidade de grau.
- Coeficiente de agrupamento (Clustering Coefficient): Mede a tend√™ncia dos vizinhos de um n√≥ estarem conectados entre si.
- Hubs (n√≥s com maior grau): S√£o os n√≥s com o maior n√∫mero de conex√µes, ou seja, os mais centrais e conectados na rede.
_ Grau do Grafo (Degree of Graph): Refere-se ao n√∫mero de conex√µes de cada n√≥. Quanto maior o grau, mais ‚Äúimportante‚Äù √© o n√≥ dentro da rede.
_ Centralidade de intermedia√ß√£o (Betweenness Centrality): Mede a import√¢ncia de um n√≥ com base na quantidade de caminhos mais curtos que passam por ele entre outros n√≥s.
_ Centralidade de proximidade (Closeness Centrality): Mede a proximidade de um n√≥ em rela√ß√£o a todos os outros n√≥s do grafo.
Essas m√©tricas ajudam a entender a estrutura e o comportamento do grafo, destacando quais n√≥s s√£o mais conectados, influentes ou pr√≥ximos uns dos outros na rede.

## üîéResultados e Insights
### Redes
Partindo para a cria√ß√£o da rede em si, com as entidades analisadas, podemos gerar os grafos necess√°rios para as an√°lises. O primeiro grafo formado foi a rede completa, contendo quatro entidades principais: pessoa, organiza√ß√£o, local e localiza√ß√£o geopol√≠tica.
```
# Criar um grafo direcionado
G3 = nx.Graph()

# Extrair as entidades nomeadas do texto
entities = [ent.text for ent in doc1.ents if ent.label_ in ['PER', 'ORG', 'GPE', 'LOC']]

# Adicionar as entidades como n√≥s no grafo
G3.add_nodes_from(entities)

# Criar rela√ß√µes entre entidades que aparecem pr√≥ximas (exemplo: na mesma senten√ßa)
for sent in doc1.sents:
    # Extrair entidades na senten√ßa
    ents_in_sent = [ent.text for ent in sent.ents if ent.label_ in ['PER', 'ORG', 'GPE', 'LOC']]
    # Adicionar arestas entre as entidades que aparecem na mesma senten√ßa
    for i in range(len(ents_in_sent)):
        for j in range(i + 1, len(ents_in_sent)):
            G3.add_edge(ents_in_sent[i], ents_in_sent[j])

# Visualizando a rede
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
nx.draw_networkx(G3, with_labels=True, node_size=3000, node_color='skyblue', font_size=10, font_weight='bold')
plt.title("Rede de Rela√ß√µes entre Entidades Nomeadas")
plt.show()
```
Com o aux√≠lio do Gephi, foi poss√≠vel fazer a formata√ß√£o do layout do grafo gerado. O primeiro grafo apresentado √© a rede do livro Joyland. Nessa rede, conseguimos visualizar uma maior conex√£o entre as entidades presentes no livro, mas tamb√©m vemos a presen√ßa de alguns n√≥s soltos. No entanto, como o livro se passa em poucos espa√ßos, a intera√ß√£o entre as entidades torna-se maior.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20NetworkJoyland.png" alt="Rede do livro Joyland." width="600" height="800"/>

Enquanto isso, o livro Depois apresenta um grafo mais complexo, com mais n√≥s com menos de duas conex√µes e um grau menor de entidades conectadas entre si. Isso reflete uma hist√≥ria com mais personagens e cen√°rios, resultando em uma rede mais dispersa e com intera√ß√µes mais distribu√≠das.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20NetworkDepois.png" alt="Rede do livro Depois." width="600" height="800"/>

Logo ap√≥s, vemos a rede da entidade ‚Äúlocaliza√ß√£o‚Äù, onde √© poss√≠vel observar que, no primeiro livro, por se passar no parque de divers√£o Joyland, a localiza√ß√£o com mais conex√µes √©, consequentemente, Joyland. Analisando as m√©tricas, rodando a fun√ß√£o calcular_metrica() citada anteriormente e presente no c√≥digo dispon√≠vel, vemos que o n√≥ Joyland possui a maior Degree Centrality da rede, indicando que √© o local mais conectado e central dentro da trama, com um n√∫mero elevado de intera√ß√µes com outras entidades.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/RedeLOCJoyland.png" alt="Rede da entidade ‚Äúlocaliza√ß√£o‚Äù para o primeiro livro." width="600" height="800"/>

Em contrapartida, a rede do segundo livro apresenta uma maior variedade de comunidades, demonstrando um n√∫mero mais elevado de locais mencionados ao longo do enredo. Al√©m disso, ao analisar suas m√©tricas, √© poss√≠vel observar valores mais pr√≥ximos entre si, o que reflete a diversifica√ß√£o dos locais e a descentraliza√ß√£o em rela√ß√£o a um √∫nico ambiente predominante.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/RedeLOCDepois.png" alt="Rede da entidade ‚Äúlocaliza√ß√£o‚Äù para o segundo livro." width="600" height="800"/>

Comentando sobre a rede de pessoas, a pr√≥xima rede destaca esses dados. Na primeira trama, o personagem Mike se destaca como um dos principais, com mais conex√µes, o que reflete sua import√¢ncia narrativa e suas intera√ß√µes frequentes com outros personagens ao longo da hist√≥ria. Isso √© vis√≠vel no grafo, onde ele aparece como um n√≥ central, com um alto grau de conectividade.

Por outro lado, Dev, apesar de ser um personagem relevante na hist√≥ria, n√£o ocupa o papel de personagem central na rede. Isso pode ser explicado pelo fato de que suas intera√ß√µes est√£o mais concentradas em subgrupos ou comunidades espec√≠ficas.

Essa descentraliza√ß√£o do papel de Dev pode ser um reflexo direto da maneira como a narrativa foi estruturada, priorizando Mike como um elemento chave de conex√£o e desenvolvimento da hist√≥ria.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20Ego2Joyland.png" alt="Rede da entidade ‚ÄúPessoas‚Äù para o primeiro livro." width="600" height="800"/>

Aqui est√° um grafo baseado na rede ego do personagem Mike.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20EgoJoyland.png" alt="Rede ego para o personagem Mike." width="600" height="800"/>

Para a segunda hist√≥ria, conseguimos observar como Liz, uma das personagens principais, tamb√©m se destaca mais do que o personagem central, Jamie. Essa an√°lise pode ser explicada pelo fato de Liz estar envolvida em diversas intera√ß√µes ao longo da trama, tanto com Jamie quanto com outros personagens, como a m√£e dele, Tia, e outras figuras centrais do enredo.

<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20Ego2Depois.png" alt="Rede da entidade ‚Äúpessoas‚Äù para o segundo livro." width="600" height="800"/>

Aqui est√° o grafo para o ego principal, Liz.
<img src="https://github.com/julianessantos/AED-II/blob/main/Unidade%203/Imagens/Rede%20EgoDepois.png" alt="Rede ego para a personagem Liz." width="600" height="800"/>

## Insights
A an√°lise revelou algumas diferen√ßas importantes entre os dois livros de King, especialmente no que diz respeito √† estrutura das intera√ß√µes entre personagens e o papel que os locais e eventos desempenham na trama.

- Densidade: Joyland apresenta um grafo mais compacto, com intera√ß√µes limitadas e uma narrativa mais focada, enquanto Depois tem um grafo mais complexo, com mais n√≥s com menos de duas conex√µes refletindo uma hist√≥ria com mais personagens e cen√°rios.
- Conex√µes: As intera√ß√µes em Joyland s√£o mais diretas e centralizadas no parque, enquanto Depois tem uma trama mais dispersa, com personagens interagindo em diferentes locais e eventos.
- Centralidade: Em Joyland, a centralidade foi dominada pelo personagem Mike, enquanto em Depois, a centralidade √© mais distribu√≠da entre v√°rios personagens, especialmente aqueles envolvidos com os eventos sobrenaturais.
## Links Relevantes
- Grafo Interativo: Acesse os grafos gerados para [Joyland](https://julianessantos.github.io/NetworkSites/RedeJoyland/RedeNetworkJoyland/) e [Depois](https://julianessantos.github.io/NetworkSites/RedeDepois/networkDepois/) e explore as intera√ß√µes entre os personagens.
- [Podcast Explicativo](https://notebooklm.google.com/notebook/5be3c582-cad2-48f0-9486-3e2081f6fbca/audio): Um podcast que explora os principais conceitos e abordagens utilizados nesta an√°lise de grafos.